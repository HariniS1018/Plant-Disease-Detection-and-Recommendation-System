{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTWNa77CukCs"
      },
      "outputs": [],
      "source": [
        "# Restart the runtime\n",
        "# !kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CormFB8rCUlW",
        "outputId": "a9988692-2901-4c1d-e693-b97a5fe9ff21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  # 40s\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OoJFsxL3CqJy"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries 5s\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdYeZpQJCrzN",
        "outputId": "1f4bb52a-2cba-4561-c1ac-f9e191be94fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 5\n",
            "Class names: ['RUST', 'LEAF SPOT (EARLY AND LATE)', 'HEALTHY', 'ALTERNARIA LEAF SPOT', 'ROSETTE']\n"
          ]
        }
      ],
      "source": [
        "# 2. Dataset Loading\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "# train_dir = os.path.join(dataset_path, \"train\")\n",
        "# test_dir = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "# Get the class names (disease names)\n",
        "class_names = os.listdir(dataset_path)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Class names: {class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWhzAQsNwe4l",
        "outputId": "a97aaf9f-4aab-4a8c-87c8-ce21e264d072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder 'RUST' has 120 images.\n",
            "Folder 'LEAF SPOT (EARLY AND LATE)' has 450 images.\n",
            "Folder 'HEALTHY' has 600 images.\n",
            "Folder 'ALTERNARIA LEAF SPOT' has 450 images.\n",
            "Folder 'ROSETTE' has 100 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_subfolders(folder_path):\n",
        "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "    folder_image_counts = {}\n",
        "\n",
        "    # Loop through each subfolder inside the given folder\n",
        "    for sub_folder in os.listdir(folder_path):\n",
        "        sub_folder_path = os.path.join(folder_path, sub_folder)\n",
        "\n",
        "        if os.path.isdir(sub_folder_path):  # Ensure it's a folder\n",
        "            image_count = sum(1 for file in os.listdir(sub_folder_path)\n",
        "                              if os.path.splitext(file)[1].lower() in image_extensions)\n",
        "            folder_image_counts[sub_folder] = image_count\n",
        "\n",
        "    return folder_image_counts\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "folder_counts = count_images_in_subfolders(folder_path)\n",
        "for folder_name, count in folder_counts.items():\n",
        "    print(f\"Folder '{folder_name}' has {count} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTfCDfwGCw6x",
        "outputId": "5dbbb9b0-2d17-4d7a-cf1c-f4fdd3cac07e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1720, 224, 224, 3)\n",
            "(1720,)\n"
          ]
        }
      ],
      "source": [
        "# 3. Data Preprocessing (6m for 2160 imgs)\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            img_path = os.path.join(class_dir, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "\n",
        "                # height, width = img.shape[:2]\n",
        "                # size = min(height, width)\n",
        "                # x = (width - size) // 2\n",
        "                # y = (height - size) // 2\n",
        "                # img = img[y : y + size, x : x + size]\n",
        "\n",
        "                original_shape = img.shape\n",
        "                image_2d = img.reshape(-1, 3)\n",
        "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "                normalized_2d = scaler.fit_transform(image_2d)\n",
        "                normalized_image = normalized_2d.reshape(original_shape)\n",
        "\n",
        "                images.append(normalized_image)\n",
        "                labels.append(class_name)\n",
        "            else:\n",
        "                print(f\"Error reading image: {img_path}\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb_w27lfDKRR",
        "outputId": "ffe295b4-3c91-4eaa-f8ef-6380ed1dea82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 4 4 ... 3 3 3]\n",
            "{0, 1, 2, 3, 4}\n"
          ]
        }
      ],
      "source": [
        "# 4. Label Encoding\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)\n",
        "print(labels_encoded)\n",
        "print(set(labels_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7pfnWHwoFsF",
        "outputId": "ecb06c02-7920-4227-eba6-a8d04c4787d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: (1376, 224, 224, 3)\n",
            "Validation data shape: (172, 224, 224, 3)\n",
            "Test data shape: (172, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# 5. Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
        ")\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FF6Ld-wTTyuI"
      },
      "outputs": [],
      "source": [
        "# 3. Data Augmentation (Important for small datasets):\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)  # Fit the datagen on the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B_hQEGwEDNol"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential(   # 3s\n",
        "      [\n",
        "          tf.keras.layers.Conv2D(\n",
        "              32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)\n",
        "          ),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "          tf.keras.layers.Dropout(0.5),\n",
        "          tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPgr6YKLDry7",
        "outputId": "1447d804-09c0-4599-fc6a-5acaab6456b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 264ms/step - accuracy: 0.2962 - loss: 1.7399 - val_accuracy: 0.4477 - val_loss: 1.2374\n",
            "Epoch 2/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.4696 - loss: 1.2019 - val_accuracy: 0.5640 - val_loss: 1.0037\n",
            "Epoch 3/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5693 - loss: 1.0128 - val_accuracy: 0.6453 - val_loss: 0.8342\n",
            "Epoch 4/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.6432 - loss: 0.8364 - val_accuracy: 0.6977 - val_loss: 0.7562\n",
            "Epoch 5/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.6932 - loss: 0.7026 - val_accuracy: 0.6744 - val_loss: 0.7692\n",
            "Epoch 6/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.7759 - loss: 0.5842 - val_accuracy: 0.7674 - val_loss: 0.6664\n",
            "Epoch 7/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8270 - loss: 0.4487 - val_accuracy: 0.7616 - val_loss: 0.6434\n",
            "Epoch 8/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.8851 - loss: 0.3594 - val_accuracy: 0.7849 - val_loss: 0.6094\n",
            "Epoch 9/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9240 - loss: 0.2418 - val_accuracy: 0.7791 - val_loss: 0.5963\n",
            "Epoch 10/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9025 - loss: 0.2372 - val_accuracy: 0.7965 - val_loss: 0.6174\n",
            "Epoch 11/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9331 - loss: 0.1744 - val_accuracy: 0.7965 - val_loss: 0.6340\n",
            "Epoch 12/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9354 - loss: 0.1475 - val_accuracy: 0.8081 - val_loss: 0.8606\n",
            "Epoch 13/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9600 - loss: 0.1185 - val_accuracy: 0.8198 - val_loss: 0.7239\n",
            "Epoch 14/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.9656 - loss: 0.0972 - val_accuracy: 0.7733 - val_loss: 0.8946\n",
            "Epoch 15/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9568 - loss: 0.1132 - val_accuracy: 0.8081 - val_loss: 0.7698\n",
            "Epoch 16/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9704 - loss: 0.0800 - val_accuracy: 0.8140 - val_loss: 0.8718\n",
            "Epoch 17/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9697 - loss: 0.0810 - val_accuracy: 0.8081 - val_loss: 0.8715\n",
            "Epoch 18/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9685 - loss: 0.0760 - val_accuracy: 0.7907 - val_loss: 1.0634\n",
            "Epoch 19/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9661 - loss: 0.1011 - val_accuracy: 0.8256 - val_loss: 0.7875\n",
            "Epoch 20/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9764 - loss: 0.0653 - val_accuracy: 0.8023 - val_loss: 0.8186\n",
            "Epoch 21/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9731 - loss: 0.0725 - val_accuracy: 0.7965 - val_loss: 0.8198\n",
            "Epoch 22/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9757 - loss: 0.0761 - val_accuracy: 0.7791 - val_loss: 0.8868\n",
            "Epoch 23/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.9649 - loss: 0.0847 - val_accuracy: 0.8198 - val_loss: 0.8598\n",
            "Epoch 24/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9731 - loss: 0.1053 - val_accuracy: 0.7791 - val_loss: 1.1250\n",
            "Epoch 25/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.9580 - loss: 0.1072 - val_accuracy: 0.7907 - val_loss: 0.7840\n",
            "Epoch 26/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.9819 - loss: 0.0469 - val_accuracy: 0.8488 - val_loss: 0.7716\n",
            "Epoch 27/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.9791 - loss: 0.0525 - val_accuracy: 0.8023 - val_loss: 1.1862\n",
            "Epoch 28/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.9781 - loss: 0.0577 - val_accuracy: 0.8256 - val_loss: 1.0245\n",
            "Epoch 29/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.9696 - loss: 0.0717 - val_accuracy: 0.8140 - val_loss: 0.7957\n",
            "Epoch 30/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9789 - loss: 0.0621 - val_accuracy: 0.8256 - val_loss: 0.8707\n",
            "Epoch 31/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9809 - loss: 0.0437 - val_accuracy: 0.8430 - val_loss: 0.7899\n",
            "Epoch 32/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9842 - loss: 0.0458 - val_accuracy: 0.8081 - val_loss: 1.0520\n",
            "Epoch 33/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9820 - loss: 0.0527 - val_accuracy: 0.7791 - val_loss: 1.1703\n",
            "Epoch 34/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9797 - loss: 0.0691 - val_accuracy: 0.8198 - val_loss: 0.7536\n",
            "Epoch 35/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9828 - loss: 0.0443 - val_accuracy: 0.8198 - val_loss: 0.8466\n",
            "Epoch 36/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9887 - loss: 0.0326 - val_accuracy: 0.8430 - val_loss: 0.7364\n",
            "Epoch 37/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9722 - loss: 0.0690 - val_accuracy: 0.8023 - val_loss: 0.9881\n",
            "Epoch 38/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9798 - loss: 0.0597 - val_accuracy: 0.7849 - val_loss: 0.8995\n",
            "Epoch 39/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.9728 - loss: 0.0661 - val_accuracy: 0.7733 - val_loss: 0.9416\n",
            "Epoch 40/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9761 - loss: 0.0829 - val_accuracy: 0.8256 - val_loss: 0.9572\n",
            "Epoch 41/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.9899 - loss: 0.0318 - val_accuracy: 0.7616 - val_loss: 1.1518\n",
            "Epoch 42/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9735 - loss: 0.0618 - val_accuracy: 0.8081 - val_loss: 0.8158\n",
            "Epoch 43/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9888 - loss: 0.0298 - val_accuracy: 0.8256 - val_loss: 0.8739\n",
            "Epoch 44/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.9931 - loss: 0.0186 - val_accuracy: 0.8430 - val_loss: 0.9354\n",
            "Epoch 45/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.9901 - loss: 0.0277 - val_accuracy: 0.7907 - val_loss: 1.0744\n",
            "Epoch 46/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.9842 - loss: 0.0432 - val_accuracy: 0.6860 - val_loss: 1.4368\n",
            "Epoch 47/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9587 - loss: 0.1080 - val_accuracy: 0.7965 - val_loss: 0.9624\n",
            "Epoch 48/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9849 - loss: 0.0436 - val_accuracy: 0.7965 - val_loss: 0.9817\n",
            "Epoch 49/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9826 - loss: 0.0477 - val_accuracy: 0.7733 - val_loss: 1.0798\n",
            "Epoch 50/50\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9835 - loss: 0.0365 - val_accuracy: 0.8198 - val_loss: 0.9057\n"
          ]
        }
      ],
      "source": [
        "# 7. Model Training # 1m\n",
        "epochs = 50      # 30\n",
        "batch_size = 42  # 32\n",
        "\n",
        "model = create_model()\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR-xAL73EMVO",
        "outputId": "0238464d-87ed-4a38-d45b-198617716cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 116.73346757888794\n",
            "Test Accuracy: 83.72092843055725\n"
          ]
        }
      ],
      "source": [
        "# 8. Model Evaluation:\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss * 100}\")\n",
        "print(f\"Test Accuracy: {accuracy * 100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCeX8rkepNld",
        "outputId": "eb961e68-6143-41df-ae53-94a23292bd65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
            "Precision: 0.8380\n",
            "Recall: 0.8372\n",
            "F1-Score: 0.8330\n",
            "Accuracy: 83.72%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "y_true = y_test\n",
        "\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')  # For multi-class classification\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkXHZHVMAgKA",
        "outputId": "3814c960-ec83-4094-bfb1-a9106df4f736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n"
          ]
        }
      ],
      "source": [
        "def perform_cross_validation(X, y, k=5, ): #X is the images and y is the labels\n",
        "    best_model_path=\"/content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models/5-fold-best-model.keras\"\n",
        "    final_model_path=\"/content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models/5-fold-final-model.keras\"\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    cv_scores = []\n",
        "    best_accuracy = 0\n",
        "    best_model = None\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):  # Use y directly\n",
        "        print(f\"Fold {fold+1}\")\n",
        "\n",
        "        X_train, X_val = X[train_index], X[val_index]\n",
        "        y_train, y_val = y[train_index], y[val_index]  # Use y directly\n",
        "\n",
        "        num_classes = len(np.unique(y))  # Get num_classes from y\n",
        "        model = create_model(num_classes)\n",
        "\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
        "\n",
        "        _, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "        cv_scores.append(accuracy)\n",
        "        print(f\"Fold {fold+1} Accuracy: {accuracy}\")\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores)}\")\n",
        "\n",
        "    if best_model:\n",
        "        print(f\"Saving best model to: {best_model_path}\")\n",
        "        best_model.save(best_model_path)\n",
        "\n",
        "    final_model = create_model(num_classes)\n",
        "    final_model.fit(X, y, epochs=10, batch_size=32, verbose=0)  # Use y directly\n",
        "\n",
        "    print(f\"Saving final model to: {final_model_path}\")\n",
        "    final_model.save(final_model_path)\n",
        "\n",
        "    return np.mean(cv_scores)\n",
        "\n",
        "num_classes = len(np.unique(y))  # Get num_classes *after* loading data\n",
        "perform_cross_validation(images, labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9G9clJfCY55",
        "outputId": "f92ccf2f-eb46-4164-9469-ba0aa7041106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685ms/step\n",
            "Predicted Class: 2, Confidence: 94.54%\n",
            "Predicted Disease: LEAF SPOT (EARLY AND LATE), Confidence: 94.54%\n"
          ]
        }
      ],
      "source": [
        "# from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    # Load image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize image to (224, 224)\n",
        "    height, width = img.shape[:2]\n",
        "    size = min(height, width)\n",
        "    x = (width - size) // 2\n",
        "    y = (height - size) // 2\n",
        "    img = img[y : y + size, x : x + size]  # Crop image to square\n",
        "\n",
        "    # Normalize the image\n",
        "    original_shape = img.shape\n",
        "    image_2d = img.reshape(-1, 3)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_2d = scaler.fit_transform(image_2d)\n",
        "    normalized_image = normalized_2d.reshape(original_shape)\n",
        "\n",
        "    # Add an extra dimension for batch size (1 image in this case)\n",
        "    normalized_image = np.expand_dims(normalized_image, axis=0)\n",
        "\n",
        "    return normalized_image\n",
        "\n",
        "# Path to the input image\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/nutriti=on_deficiency_1/dr_4_9961.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/rust_1/IMG_9015.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/healthy_leaf_1/dr_4_1013.jpg\"\n",
        "img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/late_leaf_spot_1/dr_4_9915.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/unknown_predict_image/early_leaf_spot.jpg\"\n",
        "\n",
        "# Preprocess the image\n",
        "input_img = preprocess_image(img_path)\n",
        "\n",
        "# Make prediction\n",
        "predictions = model.predict(input_img)\n",
        "predicted_class = np.argmax(predictions)  # Get class with highest probability\n",
        "confidence = np.max(predictions)  # Get confidence score\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class}, Confidence: {confidence * 100:.2f}%\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Load label encoder\n",
        "le_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/saved_models/label_encoder.pkl\"\n",
        "with open(le_path, \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# Get the disease name\n",
        "predicted_label = le.inverse_transform([predicted_class])[0]\n",
        "print(f\"Predicted Disease: {predicted_label}, Confidence: {confidence * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I-Welisjshg",
        "outputId": "023d8b7e-2c7c-4692-9ddb-d0bc108c2ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label encoder saved to: /content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models/84acc_label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "# 7. Saving the Model and Label Encoder:\n",
        "\n",
        "import pickle\n",
        "models_dir = \"/content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "model_save_path = os.path.join(models_dir, \"84acc_groundnut_disease_model.keras\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "le_save_path = os.path.join(models_dir, \"84acc_label_encoder.pkl\")\n",
        "\n",
        "with open(le_save_path, \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# print(f\"Model saved to: {model_save_path}\")\n",
        "print(f\"Label encoder saved to: {le_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxnH5cj3EsVE"
      },
      "outputs": [],
      "source": [
        "# 9. Plotting Training History\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
