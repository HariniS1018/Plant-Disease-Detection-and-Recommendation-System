{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTWNa77CukCs"
      },
      "outputs": [],
      "source": [
        "# Restart the runtime\n",
        "# !kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CormFB8rCUlW",
        "outputId": "0abc0204-4b15-4af0-c91d-207c6603c071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  # 40s\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OoJFsxL3CqJy"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries 5s\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdYeZpQJCrzN",
        "outputId": "fc86e69d-5881-425f-8a70-da1d6cacbac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 5\n",
            "Class names: ['RUST', 'LEAF SPOT (EARLY AND LATE)', 'HEALTHY', 'ALTERNARIA LEAF SPOT', 'ROSETTE']\n"
          ]
        }
      ],
      "source": [
        "# 2. Dataset Loading\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "# train_dir = os.path.join(dataset_path, \"train\")\n",
        "# test_dir = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "# Get the class names (disease names)\n",
        "class_names = os.listdir(dataset_path)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Class names: {class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWhzAQsNwe4l",
        "outputId": "005bf71c-230d-48ae-f491-44c475a49521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder 'RUST' has 120 images.\n",
            "Folder 'LEAF SPOT (EARLY AND LATE)' has 450 images.\n",
            "Folder 'HEALTHY' has 600 images.\n",
            "Folder 'ALTERNARIA LEAF SPOT' has 450 images.\n",
            "Folder 'ROSETTE' has 100 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_subfolders(folder_path):\n",
        "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "    folder_image_counts = {}\n",
        "\n",
        "    # Loop through each subfolder inside the given folder\n",
        "    for sub_folder in os.listdir(folder_path):\n",
        "        sub_folder_path = os.path.join(folder_path, sub_folder)\n",
        "\n",
        "        if os.path.isdir(sub_folder_path):  # Ensure it's a folder\n",
        "            image_count = sum(1 for file in os.listdir(sub_folder_path)\n",
        "                              if os.path.splitext(file)[1].lower() in image_extensions)\n",
        "            folder_image_counts[sub_folder] = image_count\n",
        "\n",
        "    return folder_image_counts\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "folder_counts = count_images_in_subfolders(folder_path)\n",
        "for folder_name, count in folder_counts.items():\n",
        "    print(f\"Folder '{folder_name}' has {count} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTfCDfwGCw6x",
        "outputId": "e82786b2-2548-4a79-ae13-0c97a79b0426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1720, 224, 224, 3)\n",
            "(1720,)\n"
          ]
        }
      ],
      "source": [
        "# 3. Data Preprocessing (6m for 2160 imgs)\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            img_path = os.path.join(class_dir, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "\n",
        "                height, width = img.shape[:2]\n",
        "                size = min(height, width)\n",
        "                x = (width - size) // 2\n",
        "                y = (height - size) // 2\n",
        "                img = img[y : y + size, x : x + size]\n",
        "\n",
        "                original_shape = img.shape\n",
        "                image_2d = img.reshape(-1, 3)\n",
        "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "                normalized_2d = scaler.fit_transform(image_2d)\n",
        "                normalized_image = normalized_2d.reshape(original_shape)\n",
        "\n",
        "                images.append(normalized_image)\n",
        "                labels.append(class_name)\n",
        "            else:\n",
        "                print(f\"Error reading image: {img_path}\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb_w27lfDKRR",
        "outputId": "8f9f6dc3-a561-4f4c-f033-7a45cf26a5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 4 4 ... 3 3 3]\n",
            "{0, 1, 2, 3, 4}\n"
          ]
        }
      ],
      "source": [
        "# 4. Label Encoding\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)\n",
        "print(labels_encoded)\n",
        "print(set(labels_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7pfnWHwoFsF",
        "outputId": "15bce29e-97a2-4e1b-8cb2-b0ea48663c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: (1376, 224, 224, 3)\n",
            "Validation data shape: (172, 224, 224, 3)\n",
            "Test data shape: (172, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# 5. Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
        ")\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FF6Ld-wTTyuI"
      },
      "outputs": [],
      "source": [
        "# 3. Data Augmentation (Important for small datasets):\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)  # Fit the datagen on the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_hQEGwEDNol",
        "outputId": "f6e89729-26f6-42c1-afe9-1bc457b2f010"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential(   # 3s\n",
        "    [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)\n",
        "        ),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPgr6YKLDry7",
        "outputId": "8387c9e5-5cf6-469d-d8b2-3f3b38e4ac81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - accuracy: 0.3306 - loss: 1.9382 - val_accuracy: 0.3547 - val_loss: 1.3685\n",
            "Epoch 2/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.3745 - loss: 1.3526 - val_accuracy: 0.3663 - val_loss: 1.1999\n",
            "Epoch 3/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.4767 - loss: 1.1539 - val_accuracy: 0.6337 - val_loss: 0.8818\n",
            "Epoch 4/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.5926 - loss: 0.9478 - val_accuracy: 0.6570 - val_loss: 0.9284\n",
            "Epoch 5/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6741 - loss: 0.8143 - val_accuracy: 0.7558 - val_loss: 0.6536\n",
            "Epoch 6/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.7501 - loss: 0.6325 - val_accuracy: 0.7151 - val_loss: 0.6424\n",
            "Epoch 7/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.8266 - loss: 0.4658 - val_accuracy: 0.7907 - val_loss: 0.5942\n",
            "Epoch 8/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8576 - loss: 0.3763 - val_accuracy: 0.7442 - val_loss: 0.6590\n",
            "Epoch 9/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8893 - loss: 0.3149 - val_accuracy: 0.7733 - val_loss: 0.6852\n",
            "Epoch 10/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9207 - loss: 0.2414 - val_accuracy: 0.7674 - val_loss: 0.6448\n",
            "Epoch 11/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9291 - loss: 0.2033 - val_accuracy: 0.7616 - val_loss: 0.7202\n",
            "Epoch 12/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9235 - loss: 0.1941 - val_accuracy: 0.7849 - val_loss: 0.7619\n",
            "Epoch 13/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9440 - loss: 0.1494 - val_accuracy: 0.8081 - val_loss: 0.7128\n",
            "Epoch 14/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9545 - loss: 0.1254 - val_accuracy: 0.8198 - val_loss: 0.7257\n",
            "Epoch 15/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9584 - loss: 0.1213 - val_accuracy: 0.7907 - val_loss: 0.7064\n",
            "Epoch 16/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9523 - loss: 0.1148 - val_accuracy: 0.7907 - val_loss: 0.7470\n",
            "Epoch 17/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9613 - loss: 0.1176 - val_accuracy: 0.7616 - val_loss: 0.7804\n",
            "Epoch 18/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9581 - loss: 0.1244 - val_accuracy: 0.7500 - val_loss: 1.2113\n",
            "Epoch 19/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9665 - loss: 0.0970 - val_accuracy: 0.8140 - val_loss: 0.7444\n",
            "Epoch 20/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9751 - loss: 0.0739 - val_accuracy: 0.8081 - val_loss: 0.8179\n",
            "Epoch 21/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9577 - loss: 0.1033 - val_accuracy: 0.7907 - val_loss: 1.1000\n",
            "Epoch 22/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9740 - loss: 0.0769 - val_accuracy: 0.7791 - val_loss: 0.9769\n",
            "Epoch 23/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9828 - loss: 0.0521 - val_accuracy: 0.7907 - val_loss: 0.9408\n",
            "Epoch 24/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9856 - loss: 0.0556 - val_accuracy: 0.8081 - val_loss: 0.9122\n",
            "Epoch 25/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9803 - loss: 0.0515 - val_accuracy: 0.7907 - val_loss: 1.0370\n",
            "Epoch 26/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9675 - loss: 0.0737 - val_accuracy: 0.7849 - val_loss: 0.8258\n",
            "Epoch 27/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9752 - loss: 0.0530 - val_accuracy: 0.8198 - val_loss: 0.7910\n",
            "Epoch 28/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9781 - loss: 0.0560 - val_accuracy: 0.7616 - val_loss: 0.9794\n",
            "Epoch 29/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9642 - loss: 0.0966 - val_accuracy: 0.7907 - val_loss: 0.8765\n",
            "Epoch 30/30\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9775 - loss: 0.0622 - val_accuracy: 0.8256 - val_loss: 0.9798\n"
          ]
        }
      ],
      "source": [
        "# 7. Model Training # 1m\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR-xAL73EMVO",
        "outputId": "81599b4d-effe-4020-98e8-78c42eee1da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 82.86530375480652\n",
            "Test Accuracy: 81.39534592628479\n"
          ]
        }
      ],
      "source": [
        "# 8. Model Evaluation:\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss * 100}\")\n",
        "print(f\"Test Accuracy: {accuracy * 100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCeX8rkepNld",
        "outputId": "b422616c-c8fb-45ab-8e44-ac174b7768c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
            "Precision: 0.8165\n",
            "Recall: 0.8140\n",
            "F1-Score: 0.8132\n",
            "Accuracy: 81.40%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "y_true = y_test\n",
        "\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')  # For multi-class classification\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I-Welisjshg",
        "outputId": "69e4aa29-b49e-426f-a659-12132e739f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label encoder saved to: /content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models/label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "# 7. Saving the Model and Label Encoder:\n",
        "\n",
        "import pickle\n",
        "models_dir = \"/content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "model_save_path = os.path.join(models_dir, \"81acc_groundnut_disease_model.keras\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "le_save_path = os.path.join(models_dir, \"label_encoder.pkl\")\n",
        "\n",
        "with open(le_save_path, \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# print(f\"Model saved to: {model_save_path}\")\n",
        "print(f\"Label encoder saved to: {le_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "rxnH5cj3EsVE",
        "outputId": "39274d45-e857-4679-db3f-3a67d017a741"
      },
      "outputs": [],
      "source": [
        "# 9. Plotting Training History\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOCiZopTriFG",
        "outputId": "cfcc0847-5e1f-4df8-cc3f-b2048c08c93a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Predicted Class: 2, Confidence: 67.70%\n",
            "Predicted Disease: LEAF SPOT (EARLY AND LATE), Confidence: 67.70%\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    # Load image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))  # Resize image to (224, 224)\n",
        "    height, width = img.shape[:2]\n",
        "    size = min(height, width)\n",
        "    x = (width - size) // 2\n",
        "    y = (height - size) // 2\n",
        "    img = img[y : y + size, x : x + size]  # Crop image to square\n",
        "\n",
        "    # Normalize the image\n",
        "    original_shape = img.shape\n",
        "    image_2d = img.reshape(-1, 3)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_2d = scaler.fit_transform(image_2d)\n",
        "    normalized_image = normalized_2d.reshape(original_shape)\n",
        "\n",
        "    # Add an extra dimension for batch size (1 image in this case)\n",
        "    normalized_image = np.expand_dims(normalized_image, axis=0)\n",
        "\n",
        "    return normalized_image\n",
        "\n",
        "# Path to the input image\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/nutriti=on_deficiency_1/dr_4_9961.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/rust_1/IMG_9015.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/healthy_leaf_1/dr_4_1013.jpg\"\n",
        "img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/late_leaf_spot_1/dr_4_9915.jpg\"\n",
        "\n",
        "# Preprocess the image\n",
        "input_img = preprocess_image(img_path)\n",
        "\n",
        "# Make prediction\n",
        "predictions = model.predict(input_img)\n",
        "predicted_class = np.argmax(predictions)  # Get class with highest probability\n",
        "confidence = np.max(predictions)  # Get confidence score\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class}, Confidence: {confidence * 100:.2f}%\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Load label encoder\n",
        "le_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/saved_models/label_encoder.pkl\"\n",
        "with open(le_path, \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# Get the disease name\n",
        "predicted_label = le.inverse_transform([predicted_class])[0]\n",
        "print(f\"Predicted Disease: {predicted_label}, Confidence: {confidence * 100:.2f}%\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
