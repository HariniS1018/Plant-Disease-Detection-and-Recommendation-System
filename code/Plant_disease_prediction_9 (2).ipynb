{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTWNa77CukCs"
      },
      "outputs": [],
      "source": [
        "# Restart the runtime\n",
        "# !kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CormFB8rCUlW",
        "outputId": "672aef23-c31b-4a37-c1fb-03905638989b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  # 40s\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OoJFsxL3CqJy"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries 5s\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdYeZpQJCrzN",
        "outputId": "78b61a06-323a-4704-8680-78f6dcdd7930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 5\n",
            "Class names: ['RUST', 'LEAF SPOT (EARLY AND LATE)', 'HEALTHY', 'ALTERNARIA LEAF SPOT', 'ROSETTE']\n"
          ]
        }
      ],
      "source": [
        "# 2. Dataset Loading\n",
        "dataset_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "class_names = os.listdir(dataset_path)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Class names: {class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWhzAQsNwe4l",
        "outputId": "fd58b2c8-b6f2-4ea4-ac27-54a025713a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 'RUST' has 120 images.\n",
            "Folder 'LEAF SPOT (EARLY AND LATE)' has 450 images.\n",
            "Folder 'HEALTHY' has 600 images.\n",
            "Folder 'ALTERNARIA LEAF SPOT' has 450 images.\n",
            "Folder 'ROSETTE' has 100 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_subfolders(folder_path):\n",
        "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "    folder_image_counts = {}\n",
        "\n",
        "    for sub_folder in os.listdir(folder_path):\n",
        "        sub_folder_path = os.path.join(folder_path, sub_folder)\n",
        "\n",
        "        if os.path.isdir(sub_folder_path):  # Ensure it's a folder\n",
        "            image_count = sum(1 for file in os.listdir(sub_folder_path)\n",
        "                              if os.path.splitext(file)[1].lower() in image_extensions)\n",
        "            folder_image_counts[sub_folder] = image_count\n",
        "\n",
        "    return folder_image_counts\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "folder_counts = count_images_in_subfolders(folder_path)\n",
        "for folder_name, count in folder_counts.items():\n",
        "    print(f\"Folder '{folder_name}' has {count} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTfCDfwGCw6x",
        "outputId": "1122214d-20d7-4b29-a7ca-dd2e06bfb020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1720, 224, 224, 3)\n",
            "(1720,)\n"
          ]
        }
      ],
      "source": [
        "# 3. Data Preprocessing\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            img_path = os.path.join(class_dir, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "\n",
        "                original_shape = img.shape\n",
        "                image_2d = img.reshape(-1, 3)\n",
        "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "                normalized_2d = scaler.fit_transform(image_2d)\n",
        "                normalized_image = normalized_2d.reshape(original_shape)\n",
        "\n",
        "                images.append(normalized_image)\n",
        "                labels.append(class_name)\n",
        "            else:\n",
        "                print(f\"Error reading image: {img_path}\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb_w27lfDKRR",
        "outputId": "2d764ad1-e8fe-44f6-cca8-27640ab09189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 ... 3 3 3]\n",
            "{0, 1, 2, 3, 4}\n"
          ]
        }
      ],
      "source": [
        "# 4. Label Encoding\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)\n",
        "print(labels_encoded)\n",
        "print(set(labels_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7pfnWHwoFsF",
        "outputId": "7d7b479f-020f-4c89-dfd6-9361f1119968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (1376, 224, 224, 3)\n",
            "Validation data shape: (172, 224, 224, 3)\n",
            "Test data shape: (172, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# 5. Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
        ")\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FF6Ld-wTTyuI"
      },
      "outputs": [],
      "source": [
        "# 6. Data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B_hQEGwEDNol"
      },
      "outputs": [],
      "source": [
        "# 7. Building model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential(   # 3s\n",
        "      [\n",
        "          tf.keras.layers.Conv2D(\n",
        "              32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)\n",
        "          ),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "          tf.keras.layers.Dropout(0.5),\n",
        "          tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXPSqWZHCtN8",
        "outputId": "11544d06-08d7-449f-f097-e70841f80525"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 249ms/step - accuracy: 0.3302 - loss: 1.5864 - val_accuracy: 0.3663 - val_loss: 1.3151\n",
            "Epoch 2/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 183ms/step - accuracy: 0.4168 - loss: 1.2985 - val_accuracy: 0.5174 - val_loss: 1.1225\n",
            "Epoch 3/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 188ms/step - accuracy: 0.4798 - loss: 1.2266 - val_accuracy: 0.5291 - val_loss: 1.1036\n",
            "Epoch 4/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.4778 - loss: 1.1943 - val_accuracy: 0.6221 - val_loss: 0.9085\n",
            "Epoch 5/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 234ms/step - accuracy: 0.5448 - loss: 1.0338 - val_accuracy: 0.7093 - val_loss: 0.8095\n",
            "Epoch 6/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 183ms/step - accuracy: 0.5807 - loss: 0.9810 - val_accuracy: 0.7326 - val_loss: 0.6794\n",
            "Epoch 7/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 186ms/step - accuracy: 0.6421 - loss: 0.9007 - val_accuracy: 0.7209 - val_loss: 0.6677\n",
            "Epoch 8/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 194ms/step - accuracy: 0.6716 - loss: 0.8271 - val_accuracy: 0.7384 - val_loss: 0.7030\n",
            "Epoch 9/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 184ms/step - accuracy: 0.6663 - loss: 0.8327 - val_accuracy: 0.7500 - val_loss: 0.6367\n",
            "Epoch 10/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 191ms/step - accuracy: 0.6795 - loss: 0.7450 - val_accuracy: 0.8198 - val_loss: 0.5523\n",
            "Epoch 11/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 182ms/step - accuracy: 0.7205 - loss: 0.7271 - val_accuracy: 0.8140 - val_loss: 0.5411\n",
            "Epoch 12/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 183ms/step - accuracy: 0.7109 - loss: 0.8063 - val_accuracy: 0.8198 - val_loss: 0.5245\n",
            "Epoch 13/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 182ms/step - accuracy: 0.7046 - loss: 0.7847 - val_accuracy: 0.7209 - val_loss: 0.6769\n",
            "Epoch 14/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 200ms/step - accuracy: 0.7510 - loss: 0.6916 - val_accuracy: 0.7733 - val_loss: 0.5785\n",
            "Epoch 15/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 180ms/step - accuracy: 0.7304 - loss: 0.6787 - val_accuracy: 0.8198 - val_loss: 0.4809\n",
            "Epoch 16/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 182ms/step - accuracy: 0.7211 - loss: 0.7323 - val_accuracy: 0.8372 - val_loss: 0.4728\n",
            "Epoch 17/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 183ms/step - accuracy: 0.7682 - loss: 0.6443 - val_accuracy: 0.8663 - val_loss: 0.4504\n",
            "Epoch 18/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 217ms/step - accuracy: 0.7535 - loss: 0.6388 - val_accuracy: 0.8488 - val_loss: 0.4498\n",
            "Epoch 19/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 196ms/step - accuracy: 0.7652 - loss: 0.6562 - val_accuracy: 0.8488 - val_loss: 0.3881\n",
            "Epoch 20/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 184ms/step - accuracy: 0.7843 - loss: 0.6033 - val_accuracy: 0.8314 - val_loss: 0.4072\n",
            "Epoch 21/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 184ms/step - accuracy: 0.7729 - loss: 0.5773 - val_accuracy: 0.8372 - val_loss: 0.4011\n",
            "Epoch 22/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 185ms/step - accuracy: 0.7610 - loss: 0.6413 - val_accuracy: 0.8314 - val_loss: 0.5419\n",
            "Epoch 23/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 185ms/step - accuracy: 0.7610 - loss: 0.6622 - val_accuracy: 0.8953 - val_loss: 0.3665\n",
            "Epoch 24/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 338ms/step - accuracy: 0.8069 - loss: 0.5069 - val_accuracy: 0.8372 - val_loss: 0.4326\n",
            "Epoch 25/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 336ms/step - accuracy: 0.7978 - loss: 0.5382 - val_accuracy: 0.8547 - val_loss: 0.3761\n",
            "Epoch 26/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 186ms/step - accuracy: 0.8063 - loss: 0.5202 - val_accuracy: 0.8430 - val_loss: 0.3977\n",
            "Epoch 27/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.8200 - loss: 0.5183 - val_accuracy: 0.8837 - val_loss: 0.3764\n",
            "Epoch 28/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 195ms/step - accuracy: 0.8201 - loss: 0.5119 - val_accuracy: 0.8721 - val_loss: 0.3321\n",
            "Epoch 29/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 218ms/step - accuracy: 0.8110 - loss: 0.5227 - val_accuracy: 0.8023 - val_loss: 0.4270\n",
            "Epoch 30/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 187ms/step - accuracy: 0.7849 - loss: 0.5939 - val_accuracy: 0.8721 - val_loss: 0.3361\n",
            "Epoch 31/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 188ms/step - accuracy: 0.8213 - loss: 0.4797 - val_accuracy: 0.8837 - val_loss: 0.3074\n",
            "Epoch 32/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 184ms/step - accuracy: 0.8359 - loss: 0.4242 - val_accuracy: 0.8430 - val_loss: 0.4187\n",
            "Epoch 33/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 185ms/step - accuracy: 0.8267 - loss: 0.4814 - val_accuracy: 0.8547 - val_loss: 0.3470\n",
            "Epoch 34/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 193ms/step - accuracy: 0.8095 - loss: 0.4681 - val_accuracy: 0.9070 - val_loss: 0.2642\n",
            "Epoch 35/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 181ms/step - accuracy: 0.8126 - loss: 0.5042 - val_accuracy: 0.8779 - val_loss: 0.2919\n",
            "Epoch 36/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 185ms/step - accuracy: 0.8222 - loss: 0.5094 - val_accuracy: 0.8779 - val_loss: 0.3234\n",
            "Epoch 37/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 192ms/step - accuracy: 0.8679 - loss: 0.4051 - val_accuracy: 0.9012 - val_loss: 0.2200\n",
            "Epoch 38/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 188ms/step - accuracy: 0.8331 - loss: 0.4615 - val_accuracy: 0.9012 - val_loss: 0.2845\n",
            "Epoch 39/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 184ms/step - accuracy: 0.8428 - loss: 0.4033 - val_accuracy: 0.9012 - val_loss: 0.2719\n",
            "Epoch 40/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 186ms/step - accuracy: 0.8534 - loss: 0.4114 - val_accuracy: 0.9244 - val_loss: 0.2047\n",
            "Epoch 41/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.8790 - loss: 0.3689 - val_accuracy: 0.8837 - val_loss: 0.2693\n",
            "Epoch 42/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 202ms/step - accuracy: 0.8627 - loss: 0.3780 - val_accuracy: 0.9360 - val_loss: 0.1974\n",
            "Epoch 43/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 199ms/step - accuracy: 0.8452 - loss: 0.4001 - val_accuracy: 0.9128 - val_loss: 0.2097\n",
            "Epoch 44/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 185ms/step - accuracy: 0.8537 - loss: 0.3435 - val_accuracy: 0.9244 - val_loss: 0.2126\n",
            "Epoch 45/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 190ms/step - accuracy: 0.8331 - loss: 0.4515 - val_accuracy: 0.9244 - val_loss: 0.2101\n",
            "Epoch 46/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.8743 - loss: 0.3516 - val_accuracy: 0.8895 - val_loss: 0.3071\n",
            "Epoch 47/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 186ms/step - accuracy: 0.8640 - loss: 0.3686 - val_accuracy: 0.9012 - val_loss: 0.2691\n",
            "Epoch 48/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 195ms/step - accuracy: 0.8832 - loss: 0.3190 - val_accuracy: 0.9070 - val_loss: 0.2324\n",
            "Epoch 49/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 185ms/step - accuracy: 0.8695 - loss: 0.3348 - val_accuracy: 0.9186 - val_loss: 0.2065\n",
            "Epoch 50/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9004 - loss: 0.2694 - val_accuracy: 0.9244 - val_loss: 0.1874\n",
            "Epoch 51/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 181ms/step - accuracy: 0.8780 - loss: 0.3174 - val_accuracy: 0.9070 - val_loss: 0.2633\n",
            "Epoch 52/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 202ms/step - accuracy: 0.9059 - loss: 0.2980 - val_accuracy: 0.9186 - val_loss: 0.1744\n",
            "Epoch 53/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 183ms/step - accuracy: 0.9060 - loss: 0.2560 - val_accuracy: 0.9651 - val_loss: 0.1222\n",
            "Epoch 54/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 225ms/step - accuracy: 0.9010 - loss: 0.2660 - val_accuracy: 0.9593 - val_loss: 0.1698\n",
            "Epoch 55/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 183ms/step - accuracy: 0.8869 - loss: 0.3191 - val_accuracy: 0.9593 - val_loss: 0.1427\n",
            "Epoch 56/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 180ms/step - accuracy: 0.9120 - loss: 0.2816 - val_accuracy: 0.9535 - val_loss: 0.1351\n",
            "Epoch 57/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 180ms/step - accuracy: 0.8934 - loss: 0.3164 - val_accuracy: 0.8779 - val_loss: 0.3043\n",
            "Epoch 58/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 191ms/step - accuracy: 0.9060 - loss: 0.2624 - val_accuracy: 0.9535 - val_loss: 0.1359\n",
            "Epoch 59/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 180ms/step - accuracy: 0.9243 - loss: 0.2580 - val_accuracy: 0.9535 - val_loss: 0.1260\n",
            "Epoch 60/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 192ms/step - accuracy: 0.9286 - loss: 0.2016 - val_accuracy: 0.9651 - val_loss: 0.1037\n",
            "Epoch 61/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 179ms/step - accuracy: 0.9169 - loss: 0.2754 - val_accuracy: 0.9593 - val_loss: 0.1046\n",
            "Epoch 62/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 180ms/step - accuracy: 0.9033 - loss: 0.2868 - val_accuracy: 0.9419 - val_loss: 0.1345\n",
            "Epoch 63/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 180ms/step - accuracy: 0.9103 - loss: 0.2648 - val_accuracy: 0.9651 - val_loss: 0.1069\n",
            "Epoch 64/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 196ms/step - accuracy: 0.9321 - loss: 0.1974 - val_accuracy: 0.9709 - val_loss: 0.0924\n",
            "Epoch 65/75\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 181ms/step - accuracy: 0.9135 - loss: 0.2405 - val_accuracy: 0.9477 - val_loss: 0.1559\n",
            "Epoch 66/75\n",
            "\u001b[1m 7/86\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 163ms/step - accuracy: 0.9348 - loss: 0.1800"
          ]
        }
      ],
      "source": [
        "# 8. Model Training with Augmentated Data:\n",
        "epochs = 75\n",
        "batch_size = 16\n",
        "model = create_model()\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),  # Use datagen.flow\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),  # Use validation data\n",
        "    steps_per_epoch=len(X_train) // batch_size  # Calculate steps per epoch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR-xAL73EMVO"
      },
      "outputs": [],
      "source": [
        "# 9. Model Evaluation:\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss * 100}\")\n",
        "print(f\"Test Accuracy: {accuracy * 100}\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "y_true = y_test\n",
        "\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9G9clJfCY55"
      },
      "outputs": [],
      "source": [
        "# 10. Model Prediction\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    original_shape = img.shape\n",
        "    image_2d = img.reshape(-1, 3)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_2d = scaler.fit_transform(image_2d)\n",
        "    normalized_image = normalized_2d.reshape(original_shape)\n",
        "    normalized_image = np.expand_dims(normalized_image, axis=0)\n",
        "    return normalized_image\n",
        "\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/rust_1/IMG_9015.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/train/nutrition_deficiency_1/35_1.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/healthy_leaf_1/dr_4_1013.jpg\"\n",
        "img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/late_leaf_spot_1/dr_4_9915.jpg\"\n",
        "\n",
        "input_img = preprocess_image(img_path)\n",
        "\n",
        "predictions = model.predict(input_img)\n",
        "predicted_class = np.argmax(predictions)\n",
        "confidence = np.max(predictions)\n",
        "\n",
        "predicted_label = le.inverse_transform([predicted_class])[0]\n",
        "print(f\"Predicted Disease: {predicted_label}, Confidence: {confidence * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I-Welisjshg",
        "outputId": "ad316aff-0016-49ec-e0ae-b4752ae1856c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label encoder saved to: /content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models/854acc_da_label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "# 11. Saving the Model and Label Encoder:\n",
        "\n",
        "import pickle\n",
        "models_dir = \"/content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "model_save_path = os.path.join(models_dir, \"854acc_da_groundnut_disease_model.keras\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "le_save_path = os.path.join(models_dir, \"854acc_da_label_encoder.pkl\")\n",
        "\n",
        "with open(le_save_path, \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# print(f\"Model saved to: {model_save_path}\")\n",
        "print(f\"Label encoder saved to: {le_save_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}