{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTWNa77CukCs"
      },
      "outputs": [],
      "source": [
        "# Restart the runtime\n",
        "# !kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CormFB8rCUlW",
        "outputId": "3d268562-6bdc-435b-eace-9e6d247b639f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  # 40s\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OoJFsxL3CqJy"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries 5s\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdYeZpQJCrzN",
        "outputId": "ee6dbe92-7929-44d7-dd6a-75625a00f5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 5\n",
            "Class names: ['RUST', 'LEAF SPOT (EARLY AND LATE)', 'HEALTHY', 'ALTERNARIA LEAF SPOT', 'ROSETTE']\n"
          ]
        }
      ],
      "source": [
        "# 2. Dataset Loading\n",
        "dataset_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "class_names = os.listdir(dataset_path)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Class names: {class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWhzAQsNwe4l",
        "outputId": "45a82541-4816-4ee8-87c3-e472c49d2b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder 'RUST' has 120 images.\n",
            "Folder 'LEAF SPOT (EARLY AND LATE)' has 450 images.\n",
            "Folder 'HEALTHY' has 600 images.\n",
            "Folder 'ALTERNARIA LEAF SPOT' has 450 images.\n",
            "Folder 'ROSETTE' has 100 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_images_in_subfolders(folder_path):\n",
        "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "    folder_image_counts = {}\n",
        "\n",
        "    for sub_folder in os.listdir(folder_path):\n",
        "        sub_folder_path = os.path.join(folder_path, sub_folder)\n",
        "\n",
        "        if os.path.isdir(sub_folder_path):  # Ensure it's a folder\n",
        "            image_count = sum(1 for file in os.listdir(sub_folder_path)\n",
        "                              if os.path.splitext(file)[1].lower() in image_extensions)\n",
        "            folder_image_counts[sub_folder] = image_count\n",
        "\n",
        "    return folder_image_counts\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/a_novel_groundnut_leaf_dataset\"\n",
        "folder_counts = count_images_in_subfolders(folder_path)\n",
        "for folder_name, count in folder_counts.items():\n",
        "    print(f\"Folder '{folder_name}' has {count} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTfCDfwGCw6x",
        "outputId": "882825ae-52ca-4a2b-dd71-9aa865391f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1720, 224, 224, 3)\n",
            "(1720,)\n"
          ]
        }
      ],
      "source": [
        "# 3. Data Preprocessing\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    for filename in os.listdir(class_dir):\n",
        "        if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            img_path = os.path.join(class_dir, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "\n",
        "                original_shape = img.shape\n",
        "                image_2d = img.reshape(-1, 3)\n",
        "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "                normalized_2d = scaler.fit_transform(image_2d)\n",
        "                normalized_image = normalized_2d.reshape(original_shape)\n",
        "\n",
        "                images.append(normalized_image)\n",
        "                labels.append(class_name)\n",
        "            else:\n",
        "                print(f\"Error reading image: {img_path}\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb_w27lfDKRR",
        "outputId": "149333db-b435-47b4-fca4-8e690b8c7049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 4 4 ... 3 3 3]\n",
            "{0, 1, 2, 3, 4}\n"
          ]
        }
      ],
      "source": [
        "# 4. Label Encoding\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)\n",
        "print(labels_encoded)\n",
        "print(set(labels_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7pfnWHwoFsF",
        "outputId": "da21f96b-e80b-4e15-d831-e93330f08314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: (1376, 224, 224, 3)\n",
            "Validation data shape: (172, 224, 224, 3)\n",
            "Test data shape: (172, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# 5. Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
        ")\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FF6Ld-wTTyuI"
      },
      "outputs": [],
      "source": [
        "# 6. Data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B_hQEGwEDNol"
      },
      "outputs": [],
      "source": [
        "# 7. Building model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential(   # 3s\n",
        "      [\n",
        "          tf.keras.layers.Conv2D(\n",
        "              32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)\n",
        "          ),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "          tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "          tf.keras.layers.Dropout(0.5),\n",
        "          tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXPSqWZHCtN8"
      },
      "outputs": [],
      "source": [
        "# 8. Model Training with Augmentated Data:\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "model = create_model()\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),  # Use datagen.flow\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),  # Use validation data\n",
        "    steps_per_epoch=len(X_train) // batch_size  # Calculate steps per epoch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR-xAL73EMVO",
        "outputId": "2c4156d8-18d9-4c48-b11b-db4bd95ec6e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 19.06619817018509\n",
            "Test Accuracy: 93.60465407371521\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step\n",
            "Precision: 0.9386\n",
            "Recall: 0.9360\n",
            "F1-Score: 0.9352\n",
            "Accuracy: 93.60%\n"
          ]
        }
      ],
      "source": [
        "# 9. Model Evaluation:\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss * 100}\")\n",
        "print(f\"Test Accuracy: {accuracy * 100}\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "y_true = y_test\n",
        "\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9G9clJfCY55",
        "outputId": "96b72890-4cb6-4741-ffb0-191d24e60d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Predicted Disease: LEAF SPOT (EARLY AND LATE), Confidence: 99.72%\n"
          ]
        }
      ],
      "source": [
        "# 10. Model Prediction\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    original_shape = img.shape\n",
        "    image_2d = img.reshape(-1, 3)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_2d = scaler.fit_transform(image_2d)\n",
        "    normalized_image = normalized_2d.reshape(original_shape)\n",
        "    normalized_image = np.expand_dims(normalized_image, axis=0)\n",
        "    return normalized_image\n",
        "\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/rust_1/IMG_9015.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/train/nutrition_deficiency_1/35_1.jpg\"\n",
        "# img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/healthy_leaf_1/dr_4_1013.jpg\"\n",
        "img_path = \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset/test/late_leaf_spot_1/dr_4_9915.jpg\"\n",
        "\n",
        "input_img = preprocess_image(img_path)\n",
        "\n",
        "predictions = model.predict(input_img)\n",
        "predicted_class = np.argmax(predictions)\n",
        "confidence = np.max(predictions)\n",
        "\n",
        "predicted_label = le.inverse_transform([predicted_class])[0]\n",
        "print(f\"Predicted Disease: {predicted_label}, Confidence: {confidence * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I-Welisjshg",
        "outputId": "ee505b65-5d60-4b1a-a4bf-10938ed5b042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label encoder saved to: /content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models/93acc_da_label_encoder.pkl\n"
          ]
        }
      ],
      "source": [
        "# 11. Saving the Model and Label Encoder:\n",
        "\n",
        "import pickle\n",
        "models_dir = \"/content/drive/MyDrive//Projects/Plant Disease Prediction/saved_models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "model_save_path = os.path.join(models_dir, \"93acc_da_groundnut_disease_model.keras\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "le_save_path = os.path.join(models_dir, \"93acc_da_label_encoder.pkl\")\n",
        "\n",
        "with open(le_save_path, \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "# print(f\"Model saved to: {model_save_path}\")\n",
        "print(f\"Label encoder saved to: {le_save_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
