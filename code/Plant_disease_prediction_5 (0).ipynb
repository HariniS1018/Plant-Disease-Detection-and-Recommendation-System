{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYppuP2pCW1v"
      },
      "outputs": [],
      "source": [
        "# %pip install opencv-python-headless numpy scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTWNa77CukCs"
      },
      "outputs": [],
      "source": [
        "# Restart the runtime\n",
        "# !kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CormFB8rCUlW",
        "outputId": "117886b7-4a5e-45fd-91a1-4cc47efb327b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OoJFsxL3CqJy"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdYeZpQJCrzN",
        "outputId": "d8cf4b89-5bee-40c4-e588-40f894d76ff9"
      },
      "outputs": [],
      "source": [
        "# 2. Dataset Loading\n",
        "\n",
        "dataset_path = (\n",
        "    \"/content/drive/MyDrive/Projects/Plant Disease Prediction/Groundnut_Leaf_dataset\"\n",
        ")\n",
        "train_dir = os.path.join(dataset_path, \"train\")\n",
        "test_dir = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "# Get the class names (disease names)\n",
        "class_names = os.listdir(train_dir)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Class names: {class_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WTfCDfwGCw6x"
      },
      "outputs": [],
      "source": [
        "# 3. Data Preprocessing\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for split_dir in [train_dir, test_dir]:\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(split_dir, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, (224, 224))  # Resize\n",
        "\n",
        "                    height, width = img.shape[:2]\n",
        "                    size = min(height, width)\n",
        "                    x = (width - size) // 2\n",
        "                    y = (height - size) // 2\n",
        "                    img = img[y : y + size, x : x + size]\n",
        "\n",
        "                    original_shape = img.shape\n",
        "                    image_2d = img.reshape(-1, 3)\n",
        "                    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "                    normalized_2d = scaler.fit_transform(image_2d)\n",
        "                    normalized_image = normalized_2d.reshape(original_shape)\n",
        "\n",
        "                    images.append(normalized_image)\n",
        "                    labels.append(class_name)\n",
        "                else:\n",
        "                    print(f\"Error reading image: {img_path}\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb_w27lfDKRR",
        "outputId": "a19b8b4d-04a2-4f27-9f44-a3365f30c616"
      },
      "outputs": [],
      "source": [
        "# 4. Label Encoding\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)\n",
        "print(labels_encoded)\n",
        "print(set(labels_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7pfnWHwoFsF",
        "outputId": "ba2304c5-0c0d-4578-b5ec-1b0b353d139e"
      },
      "outputs": [],
      "source": [
        "# 5. Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
        ")\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_hQEGwEDNol",
        "outputId": "c4820d6a-547e-401d-c622-00d6565c64ca"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)\n",
        "        ),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPgr6YKLDry7",
        "outputId": "3710f7ad-509d-498b-a999-949b5cda0dd2"
      },
      "outputs": [],
      "source": [
        "# 7. Model Training\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR-xAL73EMVO",
        "outputId": "8b449ab5-e530-48fd-b4f4-d993072120e5"
      },
      "outputs": [],
      "source": [
        "# 8. Model Evaluation:\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "rxnH5cj3EsVE",
        "outputId": "8fb8cfce-1860-49ac-db75-f91cfd46cae9"
      },
      "outputs": [],
      "source": [
        "# 9. Plotting Training History\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
