{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fe709",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow keras pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6248e0",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aaeae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c392e50",
   "metadata": {},
   "source": [
    "### Defining the path of dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c517e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:\\plant_disease_project\\Groundnut_Leaf_dataset\"\n",
    "labels = os.listdir(dataset_path)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0093c852",
   "metadata": {},
   "source": [
    "### Visualizing the images and Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting 12 images to check dataset\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# dataset_path = (\n",
    "#     r\"D:\\plant_disease_project\\Groundnut_Leaf_dataset\\train\\early_leaf_spot_1\"\n",
    "# )\n",
    "\n",
    "# for i in range(1, 17):\n",
    "#     plt.subplot(4, 4, i)\n",
    "#     plt.tight_layout()\n",
    "#     rand_img = imread(\n",
    "#         dataset_path + \"/\" + random.choice(sorted(os.listdir(dataset_path)))\n",
    "#     )\n",
    "#     plt.imshow(rand_img)\n",
    "#     plt.xlabel(rand_img.shape[1], fontsize=10)  # width of image\n",
    "#     plt.ylabel(rand_img.shape[0], fontsize=10)  # height of image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72acdfe6",
   "metadata": {},
   "source": [
    "### Convert the images into a Numpy array and normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "634de6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Images to array\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40ae615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = listdir(dataset_path)\n",
    "image_list, label_list = [], []\n",
    "all_labels = [\n",
    "    \"early_leaf_spot_1\",\n",
    "    \"early_rust_1\",\n",
    "    \"healthy_leaf_1\",\n",
    "    \"late_leaf_spot_1\",\n",
    "    \"nutrition_deficiency_1\",\n",
    "    \"rust_1\",\n",
    "]\n",
    "binary_labels = [0, 1, 2, 3, 4, 5]\n",
    "temp = -1\n",
    "\n",
    "# Reading and converting image to numpy array\n",
    "\n",
    "for directory in root_dir:\n",
    "    plant_image_list = listdir(f\"{dataset_path}/{directory}\")\n",
    "    temp += 1\n",
    "    for files in plant_image_list:\n",
    "        image_path = f\"{dataset_path}/{directory}/{files}\"\n",
    "        image_list.append(convert_image_to_array(image_path))\n",
    "        label_list.append(binary_labels[temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4342c08",
   "metadata": {},
   "source": [
    "### Visualize the class count and Check for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b76840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the number of classes count\n",
    "\n",
    "label_counts = pd.DataFrame(label_list).value_counts()\n",
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e275c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will observe the shape of the image.\n",
    "\n",
    "image_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the total number of the images which is the length of the labels list.\n",
    "\n",
    "label_list = np.array(label_list)\n",
    "label_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856909c1",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train, validate and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94cd8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    image_list, label_list, test_size=0.2, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24d5efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will normalize the dataset of our images. As pixel values ranges from 0 to 255 so we will divide each image pixel with 255 to normalize the dataset.\n",
    "\n",
    "x_train = np.array(x_train, dtype=np.float16) / 225.0\n",
    "x_test = np.array(x_test, dtype=np.float16) / 225.0\n",
    "x_train = x_train.reshape(-1, 256, 256, 3)\n",
    "x_test = x_test.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6dd56",
   "metadata": {},
   "source": [
    "### Performing one-hot encoding on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad404a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993fa04",
   "metadata": {},
   "source": [
    "### Creating the model architecture, compile the model and then fit it using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(32, (3, 3), padding=\"same\", input_shape=(256, 256, 3), activation=\"relu\")\n",
    ")\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c8e986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=Adam(0.0001), metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33850f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data set into training and validation data sets\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82514d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:\\Plant-Disease-Detection\\Model\\plant_disease_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223cd4a8",
   "metadata": {},
   "source": [
    "### Plot the accuracy and loss against each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(history.history[\"accuracy\"], color=\"r\")\n",
    "plt.plot(history.history[\"val_accuracy\"], color=\"b\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6869568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating model accuracy\")\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1] * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8494f",
   "metadata": {},
   "source": [
    "### Make predictions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cde775",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8ce65",
   "metadata": {},
   "source": [
    "### Visualizing the original and predicted labels for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4596256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting image to compare\n",
    "\n",
    "img = array_to_img(x_test[11])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5235c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding max value from predition list and comaparing original value vs predicted\n",
    "\n",
    "print(\"Originally : \", all_labels[np.argmax(y_test[11])])\n",
    "print(\"Predicted : \", all_labels[np.argmax(y_pred[4])])\n",
    "print(y_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c41307",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(all_labels[np.argmax(y_test[i])], \" \", all_labels[np.argmax(y_pred[1])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
